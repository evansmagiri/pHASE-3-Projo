{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1f6af6f",
   "metadata": {},
   "source": [
    "# Phase 3 Project: Predicting Bank Account Ownership for Financial Inclusion in Kenya\n",
    "\n",
    "## Business Understanding\n",
    "\n",
    "### Real-World Problem\n",
    "Despite the success of mobile money services like M-Pesa, a large portion of adults in Kenya and East Africa remain unbanked – meaning they lack a formal bank account. This limits their ability to save safely, access credit, build financial history, and fully participate in the economy. Financial exclusion is particularly high among rural residents, women, lower-education groups, and informal workers.\n",
    "\n",
    "### Stakeholders\n",
    "- Kenyan commercial banks (e.g., Equity Bank, KCB Group, Co-operative Bank)\n",
    "- Fintech companies (Safaricom/M-Pesa, mobile banking providers)\n",
    "- Central Bank of Kenya and government bodies promoting financial inclusion\n",
    "- NGOs and development organizations focused on poverty reduction\n",
    "\n",
    "### Project Objective\n",
    "Build a binary classification model to predict whether an individual has a bank account (\"Yes\" or \"No\") based on demographic, location, and access-related features from survey data.\n",
    "\n",
    "### How the Model Helps Stakeholders\n",
    "The model can identify individuals most likely to be unbanked. Banks and fintechs can use these predictions to:\n",
    "- Target outreach campaigns (e.g., mobile banking sign-ups in rural areas)\n",
    "- Design tailored products for underserved groups\n",
    "- Prioritize regions or demographics for financial literacy programs\n",
    "\n",
    "This directly supports national goals for greater financial inclusion, economic growth, and poverty reduction in Kenya.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a774fc11",
   "metadata": {},
   "source": [
    "### Loading the Dataset and Variable Definitions\n",
    "\n",
    "To begin exploring the data, I first load the main training dataset (`Train.csv`) using pandas. This file contains all the survey responses, including features and the target variable `bank_account`.\n",
    "\n",
    "I also load `VariableDefinitions.csv` to display the meaning of each column. This helps me (and stakeholders) understand what each feature represents in the real world, which is critical for interpreting results later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a93c7f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  country  year    uniqueid bank_account location_type cellphone_access  \\\n",
      "0   Kenya  2018  uniqueid_1          Yes         Rural              Yes   \n",
      "1   Kenya  2018  uniqueid_2           No         Rural               No   \n",
      "2   Kenya  2018  uniqueid_3          Yes         Urban              Yes   \n",
      "3   Kenya  2018  uniqueid_4           No         Rural              Yes   \n",
      "4   Kenya  2018  uniqueid_5           No         Urban               No   \n",
      "\n",
      "   household_size  age_of_respondent gender_of_respondent  \\\n",
      "0               3                 24               Female   \n",
      "1               5                 70               Female   \n",
      "2               5                 26                 Male   \n",
      "3               5                 34               Female   \n",
      "4               8                 26                 Male   \n",
      "\n",
      "  relationship_with_head           marital_status  \\\n",
      "0                 Spouse  Married/Living together   \n",
      "1      Head of Household                  Widowed   \n",
      "2         Other relative     Single/Never Married   \n",
      "3      Head of Household  Married/Living together   \n",
      "4                  Child     Single/Never Married   \n",
      "\n",
      "                   education_level                   job_type  \n",
      "0              Secondary education              Self employed  \n",
      "1              No formal education       Government Dependent  \n",
      "2  Vocational/Specialised training              Self employed  \n",
      "3                Primary education  Formally employed Private  \n",
      "4                Primary education        Informally employed  \n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv('./data/Train.csv')\n",
    "\n",
    "# Load variable definitions for reference\n",
    "variable_definitions = pd.read_csv('./data/VariableDefinitions.csv')\n",
    "\n",
    "# Display first few rows of the dataset\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45009fde",
   "metadata": {},
   "source": [
    "### Variable Definitions\n",
    "\n",
    "Displaying the official variable definitions helps me and any stakeholder understand exactly what each column represents. This is crucial for interpreting relationships and justifying feature inclusion later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7ba4ffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable Definitions</th>\n",
       "      <th>Unnamed: 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>country</td>\n",
       "      <td>Country interviewee is in.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>year</td>\n",
       "      <td>Year survey was done in.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uniqueid</td>\n",
       "      <td>Unique identifier for each interviewee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>location_type</td>\n",
       "      <td>Type of location: Rural, Urban</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cellphone_access</td>\n",
       "      <td>If interviewee has access to a cellphone: Yes, No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>household_size</td>\n",
       "      <td>Number of people living in one house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>age_of_respondent</td>\n",
       "      <td>The age of the interviewee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gender_of_respondent</td>\n",
       "      <td>Gender of interviewee: Male, Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>relationship_with_head</td>\n",
       "      <td>The interviewee’s relationship with the head o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>marital_status</td>\n",
       "      <td>The martial status of the interviewee: Married...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>education_level</td>\n",
       "      <td>Highest level of education: No formal educatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>job_type</td>\n",
       "      <td>Type of job interviewee has: Farming and Fishi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Variable Definitions                                         Unnamed: 1\n",
       "0                  country                         Country interviewee is in.\n",
       "1                     year                           Year survey was done in.\n",
       "2                 uniqueid             Unique identifier for each interviewee\n",
       "3            location_type                     Type of location: Rural, Urban\n",
       "4         cellphone_access  If interviewee has access to a cellphone: Yes, No\n",
       "5           household_size               Number of people living in one house\n",
       "6        age_of_respondent                         The age of the interviewee\n",
       "7     gender_of_respondent                Gender of interviewee: Male, Female\n",
       "8   relationship_with_head  The interviewee’s relationship with the head o...\n",
       "9           marital_status  The martial status of the interviewee: Married...\n",
       "10         education_level  Highest level of education: No formal educatio...\n",
       "11                job_type  Type of job interviewee has: Farming and Fishi..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable_definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7065381",
   "metadata": {},
   "source": [
    "### Dataset Overview and Shape\n",
    "\n",
    "Checking the shape and basic info gives me the total number of respondents and features. I also look for missing values early – clean data means less preprocessing later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2800155f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape (rows, columns): (23524, 13)\n",
      "\n",
      "Data types and missing values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 23524 entries, 0 to 23523\n",
      "Data columns (total 13 columns):\n",
      " #   Column                  Non-Null Count  Dtype \n",
      "---  ------                  --------------  ----- \n",
      " 0   country                 23524 non-null  object\n",
      " 1   year                    23524 non-null  int64 \n",
      " 2   uniqueid                23524 non-null  object\n",
      " 3   bank_account            23524 non-null  object\n",
      " 4   location_type           23524 non-null  object\n",
      " 5   cellphone_access        23524 non-null  object\n",
      " 6   household_size          23524 non-null  int64 \n",
      " 7   age_of_respondent       23524 non-null  int64 \n",
      " 8   gender_of_respondent    23524 non-null  object\n",
      " 9   relationship_with_head  23524 non-null  object\n",
      " 10  marital_status          23524 non-null  object\n",
      " 11  education_level         23524 non-null  object\n",
      " 12  job_type                23524 non-null  object\n",
      "dtypes: int64(3), object(10)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "print(\"Dataset shape (rows, columns):\", df.shape)\n",
    "print(\"\\nData types and missing values:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0229621f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values per column:\n",
      "country                   0\n",
      "year                      0\n",
      "uniqueid                  0\n",
      "bank_account              0\n",
      "location_type             0\n",
      "cellphone_access          0\n",
      "household_size            0\n",
      "age_of_respondent         0\n",
      "gender_of_respondent      0\n",
      "relationship_with_head    0\n",
      "marital_status            0\n",
      "education_level           0\n",
      "job_type                  0\n",
      "dtype: int64\n",
      "\n",
      "Total missing values: 0\n",
      "\n",
      "Number of duplicate rows: 0\n",
      "\n",
      "Numeric columns summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>household_size</th>\n",
       "      <th>age_of_respondent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>23524.000000</td>\n",
       "      <td>23524.000000</td>\n",
       "      <td>23524.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2016.975939</td>\n",
       "      <td>3.797483</td>\n",
       "      <td>38.805220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.847371</td>\n",
       "      <td>2.227613</td>\n",
       "      <td>16.520569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2016.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2016.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2017.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>35.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2018.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>49.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2018.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               year  household_size  age_of_respondent\n",
       "count  23524.000000    23524.000000       23524.000000\n",
       "mean    2016.975939        3.797483          38.805220\n",
       "std        0.847371        2.227613          16.520569\n",
       "min     2016.000000        1.000000          16.000000\n",
       "25%     2016.000000        2.000000          26.000000\n",
       "50%     2017.000000        3.000000          35.000000\n",
       "75%     2018.000000        5.000000          49.000000\n",
       "max     2018.000000       21.000000         100.000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nTotal missing values:\", df.isnull().sum().sum())\n",
    "\n",
    "# Check for duplicate rows\n",
    "print(\"\\nNumber of duplicate rows:\", df.duplicated().sum())\n",
    "\n",
    "# Basic statistical summary for numeric columns\n",
    "print(\"\\nNumeric columns summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019a7003",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "### Overview of Steps\n",
    "1. Drop `uniqueid` — it's just an identifier, no predictive value.\n",
    "2. Convert target `bank_account` to numeric (Yes → 1, No → 0) for modeling.\n",
    "3. Separate features (X) and target (y).\n",
    "4. Perform stratified train-test split (80/20) to preserve class distribution in both sets.\n",
    "5. Use scikit-learn Pipeline with ColumnTransformer:\n",
    "   - OneHotEncoder for categorical features\n",
    "   - StandardScaler for numeric features (optional but good practice)\n",
    "   - This prevents data leakage and makes code clean/reproducible.\n",
    "\n",
    "These steps ensure the data is ready for baseline modeling while maintaining real-world class imbalance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4741dbd",
   "metadata": {},
   "source": [
    "### Dropping Non-Predictive Column and Encoding Target\n",
    "\n",
    "`uniqueid` is a unique identifier of the form \"uniqueid_× country\" and provides no predictive information, so I drop it.\n",
    "\n",
    "I also map the target: \"Yes\" → 1, \"No\" → 0 for scikit-learn compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "100f2430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After mapping:\n",
      "bank_account\n",
      "0    20212\n",
      "1     3312\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>year</th>\n",
       "      <th>bank_account</th>\n",
       "      <th>location_type</th>\n",
       "      <th>cellphone_access</th>\n",
       "      <th>household_size</th>\n",
       "      <th>age_of_respondent</th>\n",
       "      <th>gender_of_respondent</th>\n",
       "      <th>relationship_with_head</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>education_level</th>\n",
       "      <th>job_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Yes</td>\n",
       "      <td>3</td>\n",
       "      <td>24</td>\n",
       "      <td>Female</td>\n",
       "      <td>Spouse</td>\n",
       "      <td>Married/Living together</td>\n",
       "      <td>Secondary education</td>\n",
       "      <td>Self employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>No</td>\n",
       "      <td>5</td>\n",
       "      <td>70</td>\n",
       "      <td>Female</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>No formal education</td>\n",
       "      <td>Government Dependent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>Urban</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>Male</td>\n",
       "      <td>Other relative</td>\n",
       "      <td>Single/Never Married</td>\n",
       "      <td>Vocational/Specialised training</td>\n",
       "      <td>Self employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>Rural</td>\n",
       "      <td>Yes</td>\n",
       "      <td>5</td>\n",
       "      <td>34</td>\n",
       "      <td>Female</td>\n",
       "      <td>Head of Household</td>\n",
       "      <td>Married/Living together</td>\n",
       "      <td>Primary education</td>\n",
       "      <td>Formally employed Private</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kenya</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>Urban</td>\n",
       "      <td>No</td>\n",
       "      <td>8</td>\n",
       "      <td>26</td>\n",
       "      <td>Male</td>\n",
       "      <td>Child</td>\n",
       "      <td>Single/Never Married</td>\n",
       "      <td>Primary education</td>\n",
       "      <td>Informally employed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  country  year  bank_account location_type cellphone_access  household_size  \\\n",
       "0   Kenya  2018             1         Rural              Yes               3   \n",
       "1   Kenya  2018             0         Rural               No               5   \n",
       "2   Kenya  2018             1         Urban              Yes               5   \n",
       "3   Kenya  2018             0         Rural              Yes               5   \n",
       "4   Kenya  2018             0         Urban               No               8   \n",
       "\n",
       "   age_of_respondent gender_of_respondent relationship_with_head  \\\n",
       "0                 24               Female                 Spouse   \n",
       "1                 70               Female      Head of Household   \n",
       "2                 26                 Male         Other relative   \n",
       "3                 34               Female      Head of Household   \n",
       "4                 26                 Male                  Child   \n",
       "\n",
       "            marital_status                  education_level  \\\n",
       "0  Married/Living together              Secondary education   \n",
       "1                  Widowed              No formal education   \n",
       "2     Single/Never Married  Vocational/Specialised training   \n",
       "3  Married/Living together                Primary education   \n",
       "4     Single/Never Married                Primary education   \n",
       "\n",
       "                    job_type  \n",
       "0              Self employed  \n",
       "1       Government Dependent  \n",
       "2              Self employed  \n",
       "3  Formally employed Private  \n",
       "4        Informally employed  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop uniqueid\n",
    "df = df.drop('uniqueid', axis=1)\n",
    "\n",
    "# Map target to numeric\n",
    "df['bank_account'] = df['bank_account'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Verify\n",
    "print(\"After mapping:\")\n",
    "print(df['bank_account'].value_counts())\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56a8f6a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (18819, 11) (18819,)\n",
      "Testing set shape: (4705, 11) (4705,)\n",
      "\n",
      "Target distribution in train: bank_account\n",
      "0    0.859185\n",
      "1    0.140815\n",
      "Name: proportion, dtype: float64\n",
      "Target distribution in test: bank_account\n",
      "0    0.859299\n",
      "1    0.140701\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split data into features and target\n",
    "x = df.drop('bank_account', axis=1)\n",
    "y = df['bank_account']\n",
    "\n",
    "# Stratified train-test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "print(\"Training set shape:\", x_train.shape, y_train.shape)\n",
    "print(\"Testing set shape:\", x_test.shape, y_test.shape)\n",
    "print(\"\\nTarget distribution in train:\", y_train.value_counts(normalize=True))\n",
    "print(\"Target distribution in test:\", y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d41397",
   "metadata": {},
   "source": [
    "### Preprocessing Pipeline\n",
    "\n",
    "Most features are categorical and need encoding. I use OneHotEncoder for them.\n",
    "\n",
    "Numeric features (age_of_respondent, household_size) will be scaled with StandardScaler to improve model performance (especially for logistic regression).\n",
    "\n",
    "I build a ColumnTransformer inside a Pipeline to handle everything cleanly and prevent data leakage – transformers are fitted only on the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3dcd61",
   "metadata": {},
   "source": [
    "### Identifying Categorical and Numeric Columns\n",
    "\n",
    "I separate columns into categorical and numeric lists for the ColumnTransformer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ffb8d9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns: ['country', 'location_type', 'cellphone_access', 'gender_of_respondent', 'relationship_with_head', 'marital_status', 'education_level', 'job_type']\n",
      "Numeric columns: ['year', 'household_size', 'age_of_respondent']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Categorical columns\n",
    "categorical_cols = x_train.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Numeric columns\n",
    "numeric_cols = x_train.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "print(\"Categorical columns:\", categorical_cols)\n",
    "print(\"Numeric columns:\", numeric_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45e9698",
   "metadata": {},
   "source": [
    "### Building and Fitting the Preprocessing Pipeline\n",
    "\n",
    "Now that columns are identified, I create the ColumnTransformer:\n",
    "- OneHotEncoder for categorical columns\n",
    "- StandardScaler for numeric columns\n",
    "\n",
    "I fit it only on X_train to prevent leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4842b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after preprocessing (train): (18819, 40)\n",
      "Shape after preprocessing (test): (4705, 40)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_cols),\n",
    "        ('num', StandardScaler(), numeric_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Fit on training data only\n",
    "preprocessor.fit(x_train)\n",
    "\n",
    "# Transform train and test\n",
    "x_train_processed = preprocessor.transform(x_train)\n",
    "x_test_processed = preprocessor.transform(x_test)\n",
    "\n",
    "print(\"Shape after preprocessing (train):\", x_train_processed.shape)\n",
    "print(\"Shape after preprocessing (test):\", x_test_processed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c418d9b1",
   "metadata": {},
   "source": [
    "## Modeling\n",
    "\n",
    "### Approach\n",
    "I follow an iterative modeling process as required:\n",
    "1. Start with a simple baseline: Logistic Regression (interpretable, fast, good for tabular data).\n",
    "2. Evaluate on proper metrics (not just accuracy due to imbalance).\n",
    "3. Interpret coefficients to understand feature importance.\n",
    "4. Later iterate to nonparametric models (Decision Trees, Random Forest) for potential improvement.\n",
    "\n",
    "### Baseline Model: Logistic Regression\n",
    "Logistic Regression is a strong baseline here because:\n",
    "- Linear relationships often exist in demographic/survey data.\n",
    "- Provides interpretable coefficients (odds ratios).\n",
    "- Handles encoded categorical features well after scaling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2211e695",
   "metadata": {},
   "source": [
    "### Training the Baseline Logistic Regression\n",
    "\n",
    "I combine the fitted preprocessor with LogisticRegression in a full Pipeline.\n",
    "- class_weight='balanced' to help with imbalance (penalizes mistakes on minority class more).\n",
    "- max_iter=1000 for convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9e49d4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "\n",
    "# Full pipeline: preprocessor + logistic regression\n",
    "baseline_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(class_weight='balanced', max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Fit on training data\n",
    "baseline_model.fit(x_train, y_train)\n",
    "\n",
    "# Predictions on test set\n",
    "y_pred = baseline_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3509b30",
   "metadata": {},
   "source": [
    "### Baseline Model Evaluation\n",
    "\n",
    "I evaluate on the holdout test set using:\n",
    "- Confusion Matrix\n",
    "- Classification Report (precision, recall, F1 – focus on \"Yes\" class)\n",
    "- ROC AUC (good for imbalanced data)\n",
    "\n",
    "Recall for \"Yes\" is key: we want to identify as many actual banked/unbanked people as possible for targeted outreach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2118f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[3219  824]\n",
      " [ 158  504]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.95      0.80      0.87      4043\n",
      "         Yes       0.38      0.76      0.51       662\n",
      "\n",
      "    accuracy                           0.79      4705\n",
      "   macro avg       0.67      0.78      0.69      4705\n",
      "weighted avg       0.87      0.79      0.82      4705\n",
      "\n",
      "\n",
      "ROC AUC Score: 0.865\n"
     ]
    }
   ],
   "source": [
    "# Confusion Matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['No', 'Yes']))\n",
    "\n",
    "# ROC AUC\n",
    "auc = roc_auc_score(y_test, baseline_model.predict_proba(x_test)[:, 1])\n",
    "print(f\"\\nROC AUC Score: {auc:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6a8b19",
   "metadata": {},
   "source": [
    "### Baseline Model Results & Interpretation\n",
    "\n",
    "The balanced Logistic Regression performs well:\n",
    "\n",
    "- **Recall for \"Yes\" class: 0.76** – captures 76% of individuals who actually have bank accounts. This is strong for stakeholder outreach goals.\n",
    "- **Precision for \"Yes\": 0.38** – about 38% of predicted \"Yes\" are correct (many false positives).\n",
    "- Trade-off due to class_weight='balanced': prioritizes catching the minority class.\n",
    "- **ROC AUC: 0.865** – excellent discrimination ability.\n",
    "\n",
    "**Business Implications:**\n",
    "- Model identifies a large portion of banked/unbanked individuals for targeted interventions (e.g., rural mobile banking campaigns).\n",
    "- False positives are manageable if outreach cost is low compared to value of including true positives.\n",
    "- Next: Try tree-based models (nonparametric) which may handle nonlinear patterns better and improve precision without losing too much recall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b968fa1",
   "metadata": {},
   "source": [
    "### Iteration 1: Decision Tree Classifier\n",
    "\n",
    "Decision Trees are nonparametric and can capture nonlinear relationships and interactions (e.g., job_type + location_type effects).\n",
    "\n",
    "I start with default parameters as a second baseline, then will tune later.\n",
    "No class_weight for now – compare fairly to logistic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c596964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Confusion Matrix:\n",
      "[[3635  408]\n",
      " [ 367  295]]\n",
      "\n",
      "Decision Tree Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.91      0.90      0.90      4043\n",
      "         Yes       0.42      0.45      0.43       662\n",
      "\n",
      "    accuracy                           0.84      4705\n",
      "   macro avg       0.66      0.67      0.67      4705\n",
      "weighted avg       0.84      0.84      0.84      4705\n",
      "\n",
      "\n",
      "Decision Tree ROC AUC: 0.681\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# New pipeline with Decision Tree\n",
    "tree_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Fit\n",
    "tree_model.fit(x_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred_tree = tree_model.predict(x_test)\n",
    "y_pred_proba_tree = tree_model.predict_proba(x_test)[:, 1]\n",
    "# Evaluation\n",
    "print(\"Decision Tree Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_tree))\n",
    "\n",
    "print(\"\\nDecision Tree Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_tree, target_names=['No', 'Yes']))\n",
    "\n",
    "auc_tree = roc_auc_score(y_test, y_pred_proba_tree)\n",
    "print(f\"\\nDecision Tree ROC AUC: {auc_tree:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10790644",
   "metadata": {},
   "source": [
    "### Iteration 1 Results: Decision Tree vs Logistic Regression\n",
    "\n",
    "The default Decision Tree performed worse than the balanced Logistic Regression:\n",
    "\n",
    "- Recall for \"Yes\" dropped from 0.76 to 0.45 — missing many potential outreach targets.\n",
    "- Precision slightly improved (0.38 → 0.42) but not worth the recall loss.\n",
    "- ROC AUC significantly lower (0.865 → 0.681).\n",
    "\n",
    "**Conclusion**: The linear logistic model better captures patterns in this demographic data. The tree likely overfits.\n",
    "\n",
    "**Next Iteration**: Use Random Forest (ensemble of trees) to reduce overfitting, add class_weight='balanced', and tune hyperparameters to try improving recall and AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8cdfa9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
